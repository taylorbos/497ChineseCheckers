# -*- coding: utf-8 -*-
"""497.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rp_YCTu_5MkLiSm28-amGp_vwWyRMWXX
"""

# IMPORTS AND GLOBAL VARIABLES
import numpy as np
import matplotlib.pyplot as plt 
import math
import sys

BLACK = 1 
WHITE = 2 
EMPTY = 0 
BORDER = 3

# CHINESE CHECKERS BOARD CLASS
class ChineseCheckers(object):
  def __init__(self):  
    ''' # VALUES FOR THE 3X3 BOARD
    self.board = np.array([3,3,3,3,3,1,1,0,3,1,0,2,3,0,2,2,3,3,3,3]) #3x3
    self.board_copy = np.array([3,3,3,3,3,1,1,0,3,1,0,2,3,0,2,2,3,3,3,3]) #3x3
    self.term = np.array([3,3,3,3,3,2,2,0,3,2,0,1,3,0,1,1,3,3,3,3]) #3x3
    self.values = np.array([[0,0,0,0,0,2,3,4,0,3,4,5,0,4,5,6,0,0,0,0],[0,0,0,0,0,6,5,4,0,5,4,3,0,4,3,2,0,0,0,0]])
    self.path = []
    self.board_size = 4 #3+1padding
    ''' 
    # VALUES FOR THE 5X5 BOARD
    self.board = np.array([3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 3, 1, 1, 0, 0, 0,
                           3, 1, 0, 0, 0, 2, 3, 0, 0, 0, 2, 2, 3, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3])
    self.board_copy = np.array([3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 3, 1, 1, 0, 0, 0,
                           3, 1, 0, 0, 0, 2, 3, 0, 0, 0, 2, 2, 3, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3])
    self.term = np.array([3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 0, 0, 3, 2, 2, 0, 0, 0,
                          3, 2, 0, 0, 0, 1, 3, 0, 0, 0, 1, 1, 3, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3])
    self.values = np.array([[0, 0, 0, 0, 0, 0, 0, 2, 3, 4, 5, 6, 0, 3, 4, 5, 6, 7, 0, 4, 5, 6, 7, 8, 0, 5, 6, 7, 8, 9, 0, 6, 7, 8, 9, 10, 0, 0, 0, 0, 0, 0, 0],
                            [0, 0, 0, 0, 0, 0, 0, 10, 9, 8, 7, 6, 0, 9, 8, 7, 6, 5, 0, 8, 7, 6, 5, 4, 0, 7, 6, 5, 4, 3, 0, 6, 5, 4, 3, 2, 0, 0, 0, 0, 0, 0, 0]])
    self.path = []
    self.board_size = 6  # 5+1padding
    
    self.moves = []
    self.ttable = {}
    self.adj = [1, -1, self.board_size, -self.board_size, self.board_size-1, -self.board_size+1]
    self.hop = [2, -2, 2*self.board_size, -2*self.board_size, 2*self.board_size-2, -2*self.board_size+2]
    
  # RESETS THE BOARD TO THE STARTING POSITION
  def reset(self):
    self.board = np.copy(self.board_copy)
  
  def print_values(self):
    print_str = ''
    chars = ['\n','  1','  2','  3','  4','  5','  6','  7','  8','  9',' 10']
    for n in range(2):
      for i in range(self.board_size,len(self.board)-self.board_size):
        print_str += chars[self.values[n][i]]
    print(print_str)
    
  def print_board(self):
    print_str = ''
    chars = [' .',' b',' w','\n']
    for i in range(self.board_size,len(self.board)-self.board_size):
      print_str += chars[self.board[i]]
    print(print_str)
    
  # RETURNS THE OPPONENT OF THE INPUT
  def opponent(self,p):
    if p == BLACK:
      return WHITE
    else:
      return BLACK

  def play_move(self,start,end,player):
    if (self.board[start] == player) and (self.board[end] == EMPTY):
      self.board[start] = EMPTY
      self.board[end] = player
    else:
      pass

  def remove_move(self,start,end,player):
    if (self.board[start] == EMPTY) and (self.board[end] == player):
      self.board[start] = player
      self.board[end] = EMPTY
    else:
      pass
      
  def find_moves(self,player):
    self.moves = []
    pieces = np.where(self.board==player)
    for piece in pieces[0]:
      for a in self.adj:
        if (self.board[piece+a]==EMPTY):
          self.moves.append([piece,piece+a])
      self.hop_moves(piece,piece)
    
  def hop_moves(self,og,curr):
    for i in range(len(self.adj)):
      if (self.board[curr+self.adj[i]] == BLACK) or (self.board[curr+self.adj[i]] == WHITE):
        if (self.board[curr+self.hop[i]] == EMPTY) and not ([og,curr+self.hop[i]] in self.moves):
          self.moves.append([og,curr+self.hop[i]])
          self.hop_moves(og,curr+self.hop[i])
      
  # TESTS IF THE GAME HAS ENDED AND RETURNS WHO HAS WON
  def terminal(self):
    for p in range(1,3):
      t = (self.term == p)
      v = [0,0,0]
      for b in range(len(self.board)):
        if t[b]:
          v[self.board[b]] += 1
      if v[p] == np.sum(t):
        return p
      if (v[p] == np.sum(t)-1) and (v[self.opponent(p)] == 1):
        return p
    return 0    
  
  # FINDS AND ORDERS MOVES BASED ON THE VALUE OF THE RESULTING POSITION
  def move_ordering(self,player):
    self.find_moves(player)
    valmoves = []
    for move in self.moves:
      self.play_move(move[0],move[1],player)
      value = self.get_value(player)
      valmoves.append([value,move])
      self.remove_move(move[0],move[1],player)
    sval = sorted(valmoves, key=lambda x: x[0], reverse=True)
    return ([x[1] for x in sval], [x[0] for x in sval])
  
  def get_value(self,player):
    binary = (self.board == player)
    valarr = np.multiply(binary,self.values[player-1])
    return np.sum(valarr)
  
  def copy(self):
    b = ChineseCheckers()
    b.board = np.copy(self.board)
    return b

  '''
  # THIS IS HOLDOVER CODE FROM THE SOLVER. IT USES AN OLDER VERSION OF THE ABOVE FUNCTIONS
  def switch_player(self):
    self.player = self.opponent(self.player)
    
  def hash_board(self):
    bstr = np.array2string(self.board,separator='')[1:-1]
    bstr = bstr.replace('3','')
    tint = int(bstr,3)
    return tint
  
  def win_path(self,winner): 
    self.print_board()
    pos = []
    while(True):
      moves = self.move_ordering()
      for move in moves:
        self.play_move(move[0],move[1])
        hsh = self.hash_board()
        if hsh in pos:
          self.remove_move(move[0],move[1])
          continue
        pos.append(hsh)
        t = self.terminal()
        if t > 0:
          if t == winner:
            self.print_board()
            return
          else:
            self.remove_move(move[0],move[1])
            continue
        hshv = self.ttable.get(hsh)
        if hshv == winner:
          self.print_board()
          break
        else:
          self.remove_move(move[0],move[1])
  
  def negamax(self):
    moves = self.move_ordering()
    so_far = -1
    for move in moves:
      #play move
      self.play_move(move[0],move[1])
      #self.path.append(move)
      #check if results in win
      
      winner = self.terminal()
      if winner > 0:
        if winner != self.player:
          self.remove_move(move[0],move[1])
          return (1,move)
      
      hsh = self.hash_board()
      hshv = self.ttable.get(hsh)
      if hshv == None:
        self.ttable[hsh] = 0
      else:
        if (hshv == self.player) or (hshv == 0):
          self.remove_move(move[0],move[1])
          continue
        else:
          self.remove_move(move[0],move[1])
          return(1,move)
      #move onto opponents turn
      neg = self.negamax()
      so_far = max(so_far,-neg[0])
      #undo move
      if so_far == 1:
        #hsh = self.hash_board()
        self.remove_move(move[0],move[1])
        self.ttable[hsh] = self.player
        return (so_far,move)
      self.ttable[hsh] = self.player  
      self.remove_move(move[0],move[1])
    return (so_far,move)
  
  def solve(self):
    self.ttable = {}
    winner = self.terminal()
    if (winner > 0):
      if winner == BLACK:
        print('Black wins')
        self.print_board()
        return
      if winner == WHITE:
        print('White wins')
        self.print_board()
        return
    neg = self.negamax()
    #print(neg[0])
    if neg[0] == 1:
      if self.player == BLACK:
        print('Black wins ' + str(neg[1]))
        self.win_path(BLACK)
        return
      else:
        print('White wins ' + str(neg[1]))
        self.win_path(WHITE)
        return
    else:
      if self.player == BLACK:
        print('White wins')
        self.win_path(WHITE)
        return
      else:
        print('Black wins')
        self.win_path(BLACK)
        return
    '''

class MC_Player(object):
    def __init__(self, color,N,mx):
        self.name = "Monte Carlo Simulation Based Player"
        self.version = 1.0
        self.color = color
        self.N = N
        self.max = mx

    # CHOOSE MOVE WITH HIGHEST SIMULATED WINRATE
    def play_move(self, board):
        ret = board.move_ordering(self.color)
        moves = ret[0]
        values = np.zeros(len(moves))
        pos_val = np.zeros(len(moves))
        for m in range(len(moves)):
            out = 0
            for s in range(self.N):
                r = self.simulate(board,moves[m],self.color)
                values[m] += r[0]
                pos_val[m] += r[1]
        i = np.argmax(values)
        move = moves[i]
        if values[i] == 0.0:
            move = moves[np.argmax(pos_val)]
        board.play_move(move[0],move[1],self.color)
      
    def simulate(self,board,move,color):
        b_copy = board.copy()
        b_copy.play_move(move[0],move[1],color)
        c = 0
        curr = b_copy.opponent(color)
        color_win = 0
        while(c < self.max):
            c += 1
            term = b_copy.terminal()
            if term == color:
                color_win = 1
                break
            elif term == b_copy.opponent(color):
                break
            n_move = self.get_move(b_copy,curr)
            b_copy.play_move(n_move[0],n_move[1],curr)
            curr = b_copy.opponent(curr)
        return (color_win,b_copy.get_value(color)-b_copy.get_value(b_copy.opponent(color)))
      
    # CHOOSE MOVE RANDOMLY, SKEWED BASED ON RESULTING POSITION VALUE
    def get_move(self,board,color):
        og_v = board.get_value(color)
        ret = board.move_ordering(color)
        moves = ret[0]
        v = np.where(ret[1] < og_v, og_v-1, ret[1])
        vals = np.multiply(np.divide(np.subtract(v,og_v-1),np.subtract(np.amax(v),og_v-1)),len(moves))
        distr = []
        move = moves[np.random.randint(len(moves))]
        try:
            for m in range(len(moves)):
                for i in range(math.ceil(vals[m])):
                    distr.append(m)
            move = moves[distr[np.random.randint(len(distr))]]
        except:
            pass
        return move
    
class Random_Player(object):
    def __init__(self, color):
        self.name = "Random player"
        self.version = 1.0
        self.color = color

    def play_move(self, board):
        ret = board.move_ordering(self.color)
        moves = ret[0]
        move_vals = ret[1]
        move = moves[np.random.randint(len(moves))]
        board.play_move(move[0],move[1],self.color)

class Smart_Random_Player(object):
    def __init__(self, color):
        self.name = "Smart Random player"
        self.version = 1.0
        self.color = color

    def play_move(self, board):
        #'smart' random from moves that are valued >= current pos
        og_v = board.get_value(self.color)
        ret = board.move_ordering(self.color)
        moves = ret[0]
        move_vals = ret[1]
        smart_moves = []
        for i in range(len(move_vals)):
            if move_vals[i] >= og_v:
                smart_moves.append(moves[i])
        move = moves[np.random.randint(len(moves))]
        if len(smart_moves) > 0:
            move = smart_moves[np.random.randint(len(smart_moves))]
        board.play_move(move[0],move[1],self.color)
        
class Ordered_Player(object):
    # GREEDY WITH RESPECT TO THE VALUE FUNCTION
    def __init__(self, color):
        #pass
        self.name = "Ordered player"
        self.version = 1.0
        self.color = color

    def play_move(self, board):
        ret = board.move_ordering(self.color)
        moves = ret[0]
        move_vals = ret[1]
        aw = np.argwhere(move_vals==np.amax(move_vals))
        move = moves[aw[np.random.randint(len(aw))][0]]
        board.play_move(move[0],move[1],self.color)
        
class RL_Player(object):
    def __init__(self, color):
        self.name = "Reinforcemnent Learning player"
        self.version = 1.0
        self.color = color
        self.N = 10
        self.max = 10
        self.best = 3  # randomize on best 1/self.best
        self.startmoves = {}
        self.total_depth = 0
        self.stat_ends = []
        self.weight = [0.99998981, 0.9999779 , 1.00000133]
        self.best_value = 0
        self.feature_matx = []
        self.value_vector = []
        self.alpha = 0.7
        self.depth_count = 4
        #self.board = board

    # input: board is the current class that is the board and all its methods

    def play_move(self, board):
        self.total_depth = 0
        move = self.negamax(board, self.color,0, np.NINF, np.PINF, 1)
        #print("this is the move: ",move[1][0], move[1][1])
        board.play_move(move[1][0], move[1][1], self.color)

    

    def ss_destination_score(self,color,board):
        self.values = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                                [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])

        count = 0 
        score = []
        if color == BLACK:
            arr = 0
        elif color == WHITE:
            arr = 1
        for i in board:
            if i == color:
                score.append(self.values[arr][count])
            count += 1
        np.asarray(score)
        np.square(score)
        ssq = np.sum(score)      
        return ssq
    
    def ss_center_line(self,color,board):
        self.center_score = [0,0,0,0,0,0,0,5,4,3,2,1,0,4,5,4,3,2,0,3,4,5,4,3,0,2,3,4,5,4,0,1,2,3,4,5,0,0,0,0,0,0,0]
        self.center_score = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
        count = 0
        score = []
        for i in board:
            if i == color:
                score.append(self.center_score[count])
            count += 1
        np.asarray(score)
        np.square(score)
        ssq = np.sum(score)
        return ssq

    def sum_max_vertical(self,color,board):
        self.values = np.array([[0, 0, 0, 0, 0, 0, 0, 2, 3, 4, 5, 6, 0, 3, 4, 5, 6, 7, 0, 4, 5, 6, 7, 8, 0, 5, 6, 7, 8, 9, 0, 6, 7, 8, 9, 10, 0, 0, 0, 0, 0, 0, 0],
                                [0, 0, 0, 0, 0, 0, 0, 10, 9, 8, 7, 6, 0, 9, 8, 7, 6, 5, 0, 8, 7, 6, 5, 4, 0, 7, 6, 5, 4, 3, 0, 6, 5, 4, 3, 2, 0, 0, 0, 0, 0, 0, 0]])
        count = 0 
        score = []
        if color == BLACK:
            arr = 0
        else:
            arr = 1
        for i in board:
            if i == color:
                score.append(self.values[arr][count])
            count += 1
        np.asarray(score)
        ss = np.sum(score)
        return ss
        
    def get_state_values(self,color, state):
        if color == BLACK:
            other_color = WHITE
        elif color == WHITE:
            other_color = BLACK
        best_values = []
        
        self.A1 = self.ss_destination_score(color,state)
        self.A2 = self.ss_destination_score(other_color,state)
        self.B1 = self.ss_center_line(color,state)
        self.B2 = self.ss_center_line(other_color,state)
        self.C1 = self.sum_max_vertical(color,state)
        self.C2 = self.sum_max_vertical(other_color,state)
        value = (self.weight[0]*(self.A1-self.A2) + self.weight[1]*(self.B1-self.B2) + self.weight[2]*(self.C1-self.C2))
        #print("A1: ",A1,"A2: ",A2,"B1: ",B1,"B2: ",B2,"C1: ",C1,"C2: ",C2)
        #self.value_vector.append(value)
        #self.feature_matx.append([self.weight[0]*(A1-A2),self.weight[1]*(B1-B2),self.weight[2]*(C1-C2)])
        return value



    
    def negamax(self, board, color,depth,alpha,beta,neg):
        b_copy = board.copy()
        moves = b_copy.move_ordering(color)
        value = np.NINF
        count = 0
        
        for move in moves[0]:
            # play move
            b_copy.play_move(move[0], move[1] ,color)
            # check if results in win

            winner = b_copy.terminal()
            if (winner > 0) or (depth == self.depth_count):
                value_x = self.get_state_values(color,b_copy.board)
                if (winner > 0) and color == self.color:
                    self.value_vector.append(value_x)
                    self.feature_matx.append([self.weight[0]*(self.A1-self.A2),self.weight[1]*(self.B1-self.B2),self.weight[2]*(self.C1-self.C2)])


                return (neg * self.get_state_values(color,b_copy.board),move)
                '''
                if winner != self.color:
                    return (self.get_state_values(color, b_copy.board), move)
                value = self.get_state_values(color,b_copy.board)
                if value >= self.best_value:
                    self.best_value = value
                    return (self.get_state_values(color,b_copy.board),move)
                '''


            if color == BLACK:
                #self.total_depth += 1
                value = max(value, -self.negamax(b_copy, WHITE,depth+1, -beta,-alpha,-neg)[0])
                alpha = max(alpha, value)
                if alpha >= beta:
                    break
            if color == WHITE:
                value = max(value, -self.negamax(b_copy, BLACK, depth+1, -beta, -alpha,-neg)[0])
                alpha = max(alpha, value)
                if alpha >= beta:
                    break
        return (value,move)

    def update(self):
        feature_max = np.asarray(self.feature_matx)
        value_vec = np.asarray(self.value_vector)
        #print("this is the length: ",len(feature_max))
        new_weights = np.linalg.lstsq(feature_max, value_vec, rcond=None)[0]
        update_weight = self.weight + (self.alpha * (new_weights - self.weight))
        self.weight = update_weight
        self.feature_matx = []
        self.value_vector = []

def experiment_vs(exps):
    # PLAYS exps NUMBER OF GAMES BETWEEN TWO PLAYERS AND RETURNS THE WINRATES
    # PLAYER 1 = BLACK    PLAYER 2 = WHITE
    cc = ChineseCheckers()
    print("MonteCarlo Black vs Greedy White")
    #p2 = RL_Player(WHITE)
    p1 = MC_Player(BLACK,20,4) #20,4 best according to other experiment
    p2 = Ordered_Player(WHITE)
    #p1 = Smart_Random_Player(BLACK)
    #p2 = MC_Player(WHITE,20,4)
    wins = [0,0,0]
    for x in range(exps):
      cc.reset()
      winner = 0
      c = 0
      while(c < 200):
          c += 1
          p1.play_move(cc)
          if cc.terminal() == BLACK:
              sys.stdout.write('-B')
              wins[BLACK-1] += 1
              break
          p2.play_move(cc)
          if cc.terminal() == WHITE:
              winner = WHITE
              sys.stdout.write('-W')
              wins[WHITE-1] += 1
              break
      if c == 200: #timeout
          wins[2] += 1
      #p2.update()
      #p1.update()
    print('\n',wins)
    print("----\nBlack wins:",wins[BLACK-1]/exps)
    print("White wins:",wins[WHITE-1]/exps)
    print("timeout:",wins[2]/exps)
    
def experiment_sims():
    # TESTS VARIOUS VALUES FOR DEPTH AND NUMBER OF SIMULATIONS FOR MONTE CARLO PLAYER
    cc = ChineseCheckers()
    print("Ordered Black vs MC White")
    results = [[],[],[]]
    ds = [2,4,6]
    ss = [10,15,20,25]
    p1 = Ordered_Player(BLACK)
    exps = 40
    for si in range(len(ss)): #26
      s = ss[si]
      for d in range(len(ds)):
        p2 = MC_Player(WHITE,s,ds[d])
        wins = [0,0]
        for x in range(exps):
          cc.reset()
          c = 0
          while(c < 100):
              c += 1
              p1.play_move(cc)
              if cc.terminal() == BLACK:
                  wins[BLACK-1] += 1
                  sys.stdout.write('B')
                  break
              p2.play_move(cc)
              if cc.terminal() == WHITE:
                  sys.stdout.write('W')
                  wins[WHITE-1] += 1
                  break
        sys.stdout.write('\n')
        results[d].append(wins[WHITE-1]/exps)
    print(results)
    plt.plot(ss,results[0])
    plt.plot(ss,results[1])
    plt.plot(ss,results[2])
    #plt.legend([str(ds[0]), str(ds[1])], loc='upper left')
    plt.legend([str(ds[0]), str(ds[1]), str(ds[2])], loc='upper left')
    plt.xlabel('Simulations')
    plt.ylabel('Win Rate')
    
#experiment_sims()
experiment_vs(10)